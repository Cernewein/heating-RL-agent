Search.setIndex({docnames:["DQN","basic_agent","environment","index"],envversion:{"sphinx.domains.c":1,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":1,"sphinx.domains.javascript":1,"sphinx.domains.math":2,"sphinx.domains.python":1,"sphinx.domains.rst":1,"sphinx.domains.std":1,sphinx:56},filenames:["DQN.rst","basic_agent.rst","environment.rst","index.rst"],objects:{"":{DQN:[0,0,0,"-"],agent:[1,0,0,"-"],environment:[2,0,0,"-"]},"DQN.DAgent":{optimize_model:[0,2,1,""],select_action:[0,2,1,""]},"DQN.DeepQNetwork":{forward:[0,2,1,""]},"DQN.ReplayMemory":{push:[0,2,1,""],sample:[0,2,1,""]},"DQN.Transition":{action:[0,3,1,""],next_state:[0,3,1,""],reward:[0,3,1,""],state:[0,3,1,""]},"agent.Agent":{basic_controller:[1,2,1,""],train:[1,2,1,""]},"environment.Building":{heat_pump_power:[2,2,1,""],reset:[2,2,1,""],reward:[2,2,1,""],step:[2,2,1,""]},DQN:{DAgent:[0,1,1,""],DeepQNetwork:[0,1,1,""],ReplayMemory:[0,1,1,""],Transition:[0,1,1,""]},agent:{Agent:[1,1,1,""]},environment:{Building:[2,1,1,""]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","attribute","Python attribute"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:attribute"},terms:{"class":[0,1,2],"float":[0,2],"new":2,"return":[0,1,2],Its:2,The:3,achiev:0,action:[0,2],after:[0,2],agent:3,alia:0,analog:2,ani:1,appli:0,approach:[0,1],arg:0,associ:0,attribut:2,base:[0,2],baselin:1,basic:3,basic_control:1,batch:0,batch_siz:0,build:[1,2],can:0,capabl:0,capac:0,characteris:0,chosen:[0,2],comparis:1,comput:0,connect:0,content:3,control:[0,1,2],convert:2,dagent:0,decai:0,deep:0,deepqnetwork:0,dimens:0,discount:0,doe:0,done:2,dqn:3,dynam:2,each:0,electr:2,element:0,enough:0,envelop:2,environ:[0,3],episod:1,epoch:0,eps_dec:0,eps_end:0,epsilon:[0,1],experi:0,explain:0,factor:0,fc_1_dim:0,fc_2_dim:0,field:0,file:1,first:0,flow:2,forward:0,from:[0,2],fulli:0,gamma:0,greedi:[0,1],has:2,heat:[0,1,2],heat_pump_pow:2,histor:1,how:0,index:[2,3],initialis:2,input:0,input_dim:0,insid:2,instanci:2,integ:[0,2],involv:1,later:0,layer:0,learn:[0,3],mani:0,mechan:1,mem_siz:0,memori:0,method:[0,2],minimum:0,model:2,modul:3,n_action:0,network:0,neuron:0,next:[0,2],next_stat:0,none:1,number:[0,1],number_episod:1,number_time_step:1,observ:0,off:1,one:0,optim:0,optimize_model:0,page:3,paramet:[0,1,2],pass:0,perform:[0,1],phi_e:2,pickl:1,power:2,previous:1,probabl:0,problem:0,push:0,q_tabl:1,randomli:0,rate:0,reach:1,receiv:2,replai:0,replaymemori:0,repres:[1,2],reset:2,reward:[0,1,2],rst:0,run:0,sampl:0,save:[0,1],search:3,second:0,select:[0,2],select_act:0,serv:0,should:[0,1],simul:1,size:0,space:2,start_q_tabl:1,state:[0,2],step:[0,2],storag:0,store:0,t_max:1,t_min:1,tabl:1,take:2,temperatur:[1,2],tensor:0,thi:[0,2],time:2,time_step:1,train:1,transit:[0,2],tupl:0,turn:1,until:1,updat:0,used:[0,1],valu:[0,1,2],variabl:[0,2],veri:1,via:0,want:0,when:2,which:0},titles:["The DQN agent","The basic q-learning agent","The Environment","Welcome to Deep RL for Demand-Side Management\u2019s documentation!"],titleterms:{The:[0,1,2],agent:[0,1],basic:1,deep:3,demand:3,document:3,dqn:0,environ:2,indic:3,learn:1,manag:3,side:3,tabl:3,welcom:3}})